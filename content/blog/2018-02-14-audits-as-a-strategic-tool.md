+++
author = "Sally"
categories = ["General"]
class = "bi-4"
date = "2018-02-14T15:04:00+00:00"
description = "This is the second post in the Records Sound the Same ‚Äô12 months of digital transformation‚Äô series. In this article we‚Äôre going to be talking about the idea of assessing where you are in order to set strategic direction, help identify opportunities, and spark change."
headerimg = "/img/content/blog/l/20180214-header.jpg"
tags = ["digital transformation", "reviews"]
title = "Audits as a strategic tool"
type = "post"
url = "/blog/2018/02/14/audits-as-a-strategic-tool/"
+++


<p class="lede">This is the second long-form post in the Records Sound the Same <a href="/blog/2018/01/02/12-months-of-digital-transformation/">12 months of digital transformation</a> series. In this article we‚Äôre going to be talking about the idea of assessing where you are in order to set strategic direction, help identify opportunities, and spark change.</p>

Over the years, working with people in very different environments I‚Äôve frequently heard the phrase _‚Äúif you can‚Äôt measure it, you can‚Äôt manage it‚Äù_ roll off tongues. Targets, and measurements against them are commonly the way that companies decide how well they‚Äôre doing or act to change direction. Having an accurate, informed measurement of current status is useful when we‚Äôre planning how to do that thing better in the future.

**But what does that mean when we apply it specifically to the world of digital?**

Most digital projects that I work on involve some degree of audits, where there‚Äôs work to capture the current state of play of different areas. These can be broad, but include activities like expert reviews of websites, capturing the ecosystem of systems and technologies in use, or mapping processes in order to work out where the web can help.

**The goal is that by understanding the realities of we‚Äôre at now, we can do even better in the future.**

Later in this series of posts we‚Äôre going to look at some of the above types of review in more detail, but in this instance we‚Äôre going to zoom right out to get the big picture, and look at how undertaking an audit of how you're working with digital can help **strategically**.

<figure>
<img src="/img/content/blog/l/20180214-space.jpg" alt="The Earth, from space" />
<figcaption>This is the level that we're aiming for (image public domain thanks to SpaceX)</figcaption>
</figure>

## Things to think about
Let‚Äôs start with the basics of what we‚Äôre talking about. Google‚Äôs definition of an audit is *‚Äúan official inspection of an organization's accounts, typically by an independent body.‚Äù* With our transformation strategic hat on (feel free to send in a postcard with a drawing of what this should look like, dear readers), we‚Äôre looking to inspect not financial accounts, but **our relationship with digital, technologies, and all that comes under this umbrella**.

This will involve defining a set of different areas to review, looking at whether each one is being considered at the moment, and if so how well it‚Äôs being done. Within my reviews, I tend to focus on areas under the topics of **systems and technology**; **processes**; **people, teams and culture**; **strategy, vision, and principles**. These are more inter-linked than they may be at first glance, and the findings in one area can actually be useful to understanding the others - it's important to think holistically when considering changes to a strategy.

These kind of assessments go by many names - for instance labels like ‚Äò**digital maturity audit**‚Äô are quite common. Despite using it in the title of this post, I‚Äôm not actually keen on the word ‚Äòaudit‚Äô, as I find that it comes with negative connotations for clients, and most importantly the people you may be working with to get a feel for where any of the company‚Äôs gaps are. Rather than understanding that this is a test of what can be done better as an *organisation*, individuals tend to associate the term with checking whether they *personally* aren‚Äôt complying, or are breaking rules, which can lead to some hostility. Likewise, ‚Äòmaturity‚Äô doesn‚Äôt always feel right for me - your organisation can be digitally mature and yet do certain things well or badly. Instead, I tend to refer to undertaking a **digital capability review** - ‚Äòcapability‚Äô referring to what‚Äôs possible at present and where it‚Äôs realistic to get to, and ‚Äòreview‚Äô encouraging a repeat activity.

Like in the definition of an audit, it‚Äôs also worth considering whether you can get an independent body to carry the review out, so that you can assess everything with as little bias and pre-conceptions as possible. This could be someone from outside of your organisation, who‚Äôs seen a range of people‚Äôs work with digital and can quickly spot areas of improvement (üëã). However, that‚Äôs not always possible.

If you‚Äôre not able to get outside help, you‚Äôll need someone on the inside who‚Äôs specifically tasked with shrugging off previous affiliations and taking a fresh look at the situation (note that this is often harder than it sounds!). If this is your approach, ensure that you have advance buy-in for this throughout the business - there is no point in your reviewer ensuring they‚Äôre fully free from bias and the shackles of their previous experiences, only for senior management to discount the recommendations *‚Äúbecause they‚Äôve come from Diana in IT - that lot are always sending us unrealistic suggestions.‚Äù*

## Why audits are useful strategically
At the end of your review process, your findings should mean that your organisation is in a position to:

* check that where you *actually* are matches where you *think* you are.
* quickly draw attention to problematic or well-performing areas.
* identify areas of opportunity.
* start further conversations.
* use the above to help inform your strategy for the future - how you‚Äôre going to make change happen.

The point about conversations is particularly key. The review will deal more in terms of ‚Äòwhats‚Äô and ‚Äòhows‚Äô, and won‚Äôt necessarily be able to uncover all of the whys - these are better picked apart by thinking about root causes (which we‚Äôll look at in more detail in June) - or provide immediate solutions. At the end of (or even during) the review you should be prepared to have some potentially difficult and complex conversations about what‚Äôs been found, and then start to dig deeper into some aspects.

What a review *will* do is tell you what‚Äôs happening, and how well. You‚Äôll gain a bird‚Äôs eye view of different areas, all of which add up to your overall relationship with digital and technology. Whilst there may be opinions within the business of what is going well, what could be better, or where there are some opportunities, a review will help to ground these, capture reality, and present findings for people to quickly digest.

As I alluded to when talking about naming, reviews can also be useful to track progress and action over time. How long have problems been going on for? Are they actually improving? By standardising the set of areas that you look at, you can see the evolution (or otherwise!) of points of focus.

Because this, of course, is our ultimate goal. By gaining all of the facts, we can then use these to help set our strategy. We‚Äôll need to think about our priorities (the March article will cover prioritisation methods), what‚Äôs realistic, and what will make a difference.

But we‚Äôve talked too long. Let‚Äôs put everything together into a step-by-step process that you can follow.

## Carrying out your digital capability review
Our review will typically have three main parts: **before, during, and after**.

### Before

**1) Get buy in, decide the scope, talk about a plan for the ‚Äòafter‚Äô part.**

**2) Choose your reviewer.**

**3) Based on the scope, set out your assessment criteria.**  
These will be unique to each situation, but below is a link to a set of examples for you to build on. What you want to do here is to ensure each element being reviewed has a clear progression of gradings working up to your definition of what good looks like, and ultimately your ideal vision.

For example, one area that you may look at is how the business stores customer details:

* At one end of the scale may be paper-based records.
* The next level may be staff holding information individually (locally shared spreadsheets).
* Next could be collaborative, cloud-based spreadsheets.
* You may consider good practice to be using a dedicated CRM system.
* Your ideal vision may be to store customer data in specialist CRM software, with an API available to surface it to an area on your website where customers can directly update their information and preferences.

I don‚Äôt suggest using any more than 5 steps for this, but the number that you settle on should work well when all of the areas being assessed are considered.

<a class="button large" href="https://docs.google.com/spreadsheets/d/18UySMHetoXp27_as4QhdHtPCqbKvFjy-Ks92APScyrk/edit?usp=sharing">View spreadsheet</a>

**4) Plan how you will get this information.**  
Who do you need to speak to, what do you need to review?

### During

**5) Identify whether each of your review points are being considered at the moment.**  
Make this yes or no - no ‚Äòsort of‚Äôs allowed, as we‚Äôll cover this in the next step.

**6) How well is each one being done?**  
This is where we see how far up the ideal ladder we can tick.

**7) Capture additional notes.**  
Aim to capture the rationale and examples behind each classification you make - this will come in useful when you‚Äôre feeding back. Other suggestions or recommendations may crop up during your investigations, and these are important not to lose.

**8) Decide how the information needs to be presented.**  
Visual is good.  If you‚Äôre using a template similar to the spreadsheet above, you‚Äôll automatically end up with a visualisation of sorts, but radar charts (illustrated below) are also often a good bet.

<figure>
<img src="/img/content/blog/l/20180214-sheet.jpg" alt="Screenshot of the above linked spreadsheet" style="max-width:600px;" />
<figcaption>Just by filling in a spreadsheet we can produce a form of visualisation</figcaption>
</figure>

<p data-height="365" data-theme-id="light" data-slug-hash="wyrwgN" data-default-tab="result" data-user="greywillfade" data-embed-version="2" data-pen-title="Radar Chart" class="codepen">See the Pen <a href="https://codepen.io/greywillfade/pen/wyrwgN/">Radar Chart</a> by SJ (<a href="https://codepen.io/greywillfade">@greywillfade</a>) on <a href="https://codepen.io">CodePen</a>.</p>
<script async src="https://production-assets.codepen.io/assets/embed/ei.js"></script>
(Pen adapted from <a href="https://codepen.io/HughieW/pen/MwBNNV">original</a> by Hughie Wilmshurst)

### After

**9) Feed back to the business.**  
This is where the discussion starts, but try to avoid finger-pointing. Keep that neural perspective that served you well throughout doing the review. Be prepared to explain the rationale behind why you‚Äôve scored things the way that you did (here‚Äôs where the notes come in handy). If you have a previous review(s) to compare with, bring up any important comparisons with results from the past.

What you‚Äôll find, especially if you‚Äôve visualised the results, is that there should be a clear shape of how you‚Äôre doing. A key point here is that it‚Äôs *extremely* unlikely that you‚Äôll be getting top marks across the board, and that the whole point of this exercise is that you‚Äôre looking for opportunities to be better - embrace those lower scores! Maybe you‚Äôre average across the board, in which case you‚Äôll have a range of options to focus on. Maybe you‚Äôre almost there in one area, and you want to do a final push of improvements before looking at other things. Or perhaps there‚Äôs an enormous set of red flags that you had no idea about, and everyone‚Äôs got to jump on them.

What this exercise will do is to provide a framework for you to surface the status of different points, capture evidence around them, and give people a central communication aid to refer to and rally behind.

**10) Where you have suggestions for improvements, make them**

**11) Undertake a group impact/effort/prioritisation activity for problem areas, or areas of opportunity.** (We‚Äôll look at this in March)

**12) Decide how many areas are *realistic* to address in the next 3 months, 6 months, year, and allocate them to a timeframe.**

**13) Update your strategy and make a commitment to follow up activities or actionable next steps to make the change happen.**

**14) Schedule your next review!**


## Applying this to your own situation
As with most activities that we‚Äôre going to be doing, you‚Äôll need to customise the suggestions here to your situation. For very large businesses you may find that there‚Äôs huge disparity between departments, and that the results start to become too complicated. You can either cover this with smaller reviews to feed into an overall picture, or by catering for it by extending the criteria that you use to be a bit more conditional.

Whilst this post focuses on use by businesses and other organisations, individuals can also use these principles to help you with your own strategy - you can keep the categories, but tweak the points.

Whether you‚Äôre looking to carry out a full-blown official review or something a little bit more light touch, I‚Äôd like to set the following as this month‚Äôs activity:

**1) Thinking about your situation and using the above spreadsheet as a starting prompt, collect together a set of review points under each of the headings below.**

* Systems and technology
* Processes
* People, teams, and culture
* Strategy, vision, and principles

**2) Get someone else to look at your points - do they make sense? Is there anything that‚Äôs missing?**

**3) Think about what this tells you about the organisation, and consider carrying out a full review using the review points you‚Äôve collected.**


## And finally‚Ä¶
Whilst the spreadsheet above contains some examples of the kind of areas that I typically look at when undertaking a digital capability review for my clients, it‚Äôs not my full set of points and isn‚Äôt reflective of variants for different industries, technology focus, or level of detail needed.

The plan is to create an online tool to better support clients and other people who may want a light-touch way to reflect on areas where they may be able to make improvements. Stay in touch if you‚Äôd like to hear more - email **hello@recordssoundthesame.com** with a bit about your situation and any suggestions for what you‚Äôd like to see if you‚Äôd like to be kept in the loop!
